import pandas as pd
import os
import subprocess

SAMPLES = ["A32095_3_lanes_dupsFlagged", "A32102_3_lanes_dupsFlagged", "A32115_3_lanes_dupsFlagged"]
SAMPLES = SAMPLES[0]
rule all:
	input:
		expand("aggregated/{sample}.bam", sample=SAMPLES)


def get_read_groups(file_path):
	path = "samtools view -H /scratch/shahlab_tmp/sbeatty/biof-209/input_test/" + file_path + ".bam | grep 'RG' | awk '{print $2}'"
	read_groups = subprocess.check_output(path, shell=True).decode("utf-8").split("\n")
	read_groups = pd.Series(read_groups)
	read_groups = read_groups[read_groups != ""]
	read_groups = read_groups.str.replace("[A-Z:]","").tolist()
	return read_groups

rule aggregate_inputs:
	input:
		"/scratch/shahlab_tmp/sbeatty/biof-209/input_test/{sample}.bam"
	output:
		"input_files/{sample}.bam"
	shell:
		"ln -s {input} {output}"

checkpoint RG_splitting:
	input:
		"input_files/{sample}.bam"
		#expand("/scratch/shahlab_tmp/sbeatty/biof-209/input_test/{sample}.bam", sample=SAMPLES)
		#read_groups = lambda wildcards: get_read_groups("test_output/"+wildcards.sample + ".bam")
	output:
		directory("split_groups/{sample}")
	params:
		read_groups = lambda wildcards: get_read_groups(wildcards.sample)
	run:
		if not os.path.exists('split_groups{wildcards.sample}'):
			shell("mkdir split_groups/{wildcards.sample}")
		for RG_i in params.read_groups:
			shell("echo " + RG_i),
			#shell("cd split_groups/{wildcards.sample}/ ; touch " + RG_i + ".bam")
			shell("cd split_groups/{wildcards.sample}; samtools split ../../input_files/{wildcards.sample}.bam -f %\!.%.")


				##### use a lamda function that returns the list of read groups 

rule sort_name:
    input:
        "split_groups/{sample}/{i}.bam"
    output:
        "sorted_bam/{sample}/{i}.sorted.bam"
    shell:
        """
        java -jar /gsc/software/linux-x86_64-centos6/picardtools-2.4.1/picard.jar SortSam \
      	I={input} \
      	O={output} \
      	SORT_ORDER=coordinate
		"""


#rule bam_to_fastq:
#    input:
#        "sorted_bam/{sample}.sorted.bam"
#    output:
#        fastq1="reads/{sample}_R1.fastq", 
#        fastq2="reads/{sample}_R2.fastq"
#    log:
#        "logs/bam_to_fastq/{sample}.log"
#    shell:
#        "bedtools bamtofastq -i {input} -tags -fq {output.fastq1} -fq2 {output.fastq2}"


rule temp:
	input:
		"sorted_bam/{sample}/{i}.sorted.bam"
	output:
		"intermediate/{sample}/{i}.bam"
	shell:
		"cp {input} {output}"

def get_samples_and_readgroups(wildcards):
    checkpoint_output = checkpoints.RG_splitting.get(**wildcards).output[0]
    return expand("intermediate/{sample}/{i}.bam", sample = wildcards.sample, i = glob_wildcards(os.path.join(checkpoint_output,"{i}.bam")).i)   

rule merge:
    input:
        get_samples_and_readgroups
    output:
        "aggregated/{sample}.bam"
    log:
    	"log/{sample}.log"
    run:
        shell("echo {input}")
        shell("touch {output}")